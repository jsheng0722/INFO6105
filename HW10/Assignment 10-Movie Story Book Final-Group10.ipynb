{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b03b619",
   "metadata": {},
   "source": [
    "## Preparation:\n",
    "#### Prerequsite:\n",
    "- please uncompress all image.zip.\n",
    "#### Environment: \n",
    "- Mac with M2 chip,please download pymc version instead of pymc3 version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8fe28",
   "metadata": {},
   "source": [
    "## Main Story Summary\n",
    "In the year 2078, the father of a scientist decided to build an artificial intelligence dog in order to make it easier to keep a dog. However, there was a problem with the AI dog's emotional setting, which caused it to go crazy. In the process of playing with a child, the AI dog lost control and blinded the innocent child.\n",
    "His father suffered a heavy blow because of the family misfortune, he turned his anger on himself, the pressure of public opinion in the media and the judgment of the scientific community depressed him, and his career was depressed. In life, he could not earn money, his family status declined, and even suffered violence from his wife.\n",
    "Years of backlog finally made my father choose to commit suicide. His body was found by an AI dog, which attracted the attention of the police. The police immediately regarded the wife as an important suspect and launched an investigation.\n",
    "At the same time, the emotional tone and mental journey of the AI dog is also the same as that of the male master. With the help of the child, it looks for evidence that the father committed suicide rather than homicide, as suicide pills were left at the scene. However, in the course of the investigation, the AI dog accidentally ingested the pill, resulting in dysfunction, which is worrying.\n",
    "During the repair, technicians found recorded evidence that the father had been suicidal. The court eventually found that there was no doubt and the wife was released.\n",
    "Finally, the truth of the case came to light. The family tragedy becomes an unexpected and confusing story.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85165737",
   "metadata": {},
   "source": [
    "## Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ded358",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='image/poster/poster.png', width=400)\n",
    "chinese_font = \"CN-Regular.ttf\"\n",
    "english_font = \"Roboto-Regular.ttf\"\n",
    "# chinese_font_1 = \"HW5_scene2/CN-Regular.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as pili, ImageOps as piliops\n",
    "image = pili.open('image/poster/poster.png')\n",
    "w,h = image.size\n",
    "w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08952da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set crop area (left, upper, right, lower)\n",
    "crop_area = (820, 0, 2020, 1200) # 1200*1200\n",
    "# crop the image\n",
    "cropped_image = image.crop(crop_area)\n",
    "# show cropped image\n",
    "cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image.save('image/poster/poster2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98792f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "piliops.expand(pili.open('image/poster/poster2.png'), border=(0,400),fill='black').save('image/poster/poster2.png')\n",
    "piliops.expand(pili.open('image/poster/poster2.png'), border=(10,10),fill='white').save('image/poster/poster2.png')\n",
    "piliops.expand(pili.open('image/poster/poster2.png'), border=(10,10),fill='black').save('image/poster/poster3.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98dce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='image/poster/poster3.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster = pili.open('image/poster/poster3.png')\n",
    "poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85bd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "poster.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw as pilid, ImageFont as pilf\n",
    "image = pili.open('image/poster/poster3.png')\n",
    "draw = pilid.Draw(image)\n",
    "def text_t(text_str, font_path, font_size, text_color, text_position):\n",
    "    font = pilf.truetype(font_path,font_size)\n",
    "    draw.text(text_position,text_str,font=font,fill=text_color)\n",
    "text_t(\"AI·Dog\",english_font,200,(255,255,255),(80,60))\n",
    "# text = \"AI Dog\"\n",
    "# font = pilf.truetype(\"arial\", 200)\n",
    "# text_color = (255, 255, 255) # white\n",
    "# text_position = (80, 60)\n",
    "# draw.text(text_position, text, font=font, fill=text_color)\n",
    "\n",
    "text_t(u\"艾狗\",chinese_font,96,(255,255,255),(600,280))\n",
    "# text_1 = u\"艾狗\"\n",
    "# font_1 = pilf.truetype(\"c:/windows/fonts/dengl.ttf\", 96)\n",
    "# text_position_1 = (600, 280)\n",
    "# draw.text(text_position_1, text_1, font=font_1, fill=text_color)\n",
    "\n",
    "# New Year Release, Powerfully Striking\n",
    "def middle_text(text_str, font_path, font_size, text_color, height):\n",
    "    font = pilf.truetype(font_path,font_size)\n",
    "    bl,bt,br,bb = font.getbbox(text_str)\n",
    "    bw = br-bl\n",
    "    text_pos = ((image.width - bw)//2,height)\n",
    "    draw.text(text_pos,text_str,font=font,fill=text_color)\n",
    "middle_text(\"2     \",english_font,150,(255,0,0),image.height-300)\n",
    "middle_text(\"    4\",english_font,200,(255,255,255),image.height-325)\n",
    "for i in range(2):\n",
    "    middle_text((i*' ') + r\"        月      日\",chinese_font,80,(255,220,0),image.height-220+(i*5))\n",
    "\n",
    "middle_text(\"Feb. 4\",english_font,270,(0,0,255),image.height-570)\n",
    "middle_text(\"Feb. 4\",english_font,250,(255,255,0),image.height-550)\n",
    "middle_text(\"New Year Release, Powerfully Striking\",english_font,36,(200,0,0),image.height-130)\n",
    "\n",
    "def col_text(text_str, font_path, font_size, text_color, text_position):\n",
    "    x,y = text_position\n",
    "    font = pilf.truetype(font_path,font_size)\n",
    "    for c in text_str:\n",
    "        draw.text((x,y),c,font=font,fill=text_color)\n",
    "        y += font.getbbox(c)[3]- font.getbbox(c)[1]+10\n",
    "text_year_pos = (image.width-250,150)\n",
    "\n",
    "col_text(\"2078\",\"arial.ttf\",150,(255,255,255),text_year_pos)\n",
    "\n",
    "col_text(\"The  year  two  thousand\",english_font,30,(255,255,255),(text_year_pos[0]-30,text_year_pos[1]-20))\n",
    "col_text(\"and  seventy|eight\",english_font,30,(255,255,255),(text_year_pos[0]+100,text_year_pos[1]+20))\n",
    "\n",
    "\n",
    "image.save('image/poster/poster4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='image/poster/poster4.png',width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pili.open('image/poster/poster4.png').convert('RGBA')\n",
    "\n",
    "TINT_COLOR = (0, 0, 0)  # Black\n",
    "TRANSPARENCY = .25  # Degree of transparency, 0-100%\n",
    "OPACITY = int(255 * TRANSPARENCY)\n",
    "\n",
    "overlay = pili.new('RGBA', image.size, TINT_COLOR+(0,))\n",
    "draw = pilid.Draw(overlay)\n",
    "\n",
    "font = pilf.truetype(english_font, 42)\n",
    "text = \"\"\"       Li-Hsin Fu         Yayan Li         Jihui Sheng         Yuxin Li\"\"\"\n",
    "# text1 = \"\"\"\\n\n",
    "#         Yuxin Li\\n\n",
    "#         Jihui Sheng\"\"\"\n",
    "l,t,r,b = font.getbbox(text)\n",
    "w, h = r-l,b-t\n",
    "\n",
    "# l1,t1,r1,b1 = font.getbbox(text1)\n",
    "# w1, h1 = r1-l1,b1-t1\n",
    "\n",
    "num_lines = len(text.split('\\n'))\n",
    "# num_lines1 = len(text1.split('\\n'))\n",
    "print(num_lines, w, h)\n",
    "# print(num_lines1, w1, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1317b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, image.height - (1.6*num_lines)*(h)\n",
    "# x1, y1 = 160, image.height - (2.1*num_lines1)*(h1)\n",
    "# x,y,x1,y1\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ceb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw.rectangle((x, y, x + w, y + h), fill='black')\n",
    "#draw.rectangle((x, y, x + w, y + 4*h), fill=TINT_COLOR+(OPACITY,))\n",
    "draw.rectangle((x+20, y, x + image.width-20, y + (2.1*num_lines)*(h)), fill=TINT_COLOR+(OPACITY,))\n",
    "draw.text((x, y), text, fill=(150, 150, 150), font=font)\n",
    "\n",
    "# draw.rectangle((x1, y1, x1 + image.width - 200, y1 + (2.1*num_lines1)*(h1)), fill=TINT_COLOR+(OPACITY,))\n",
    "# draw.text((x1, y1), text1, fill=(209, 239, 8), font=font)\n",
    "\n",
    "# Alpha composite these two images together to obtain the desired result.\n",
    "image = pili.alpha_composite(image, overlay)\n",
    "image = image.convert(\"RGB\") # Remove alpha for saving in jpg format.\n",
    "image.save('image/result/poster.png')\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d304a",
   "metadata": {},
   "source": [
    "## Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rec(f,text,text_color,TINT_COLOR,TRANSPARENCY,font_type,font_size):\n",
    "    image = pili.open(f).convert('RGBA')\n",
    "    image = image.resize((400,300))\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "    overlay = pili.new('RGBA', image.size, TINT_COLOR+(0,))\n",
    "    draw = pilid.Draw(overlay)\n",
    "    font = pilf.truetype(font_type, font_size)\n",
    "    l,t,r,b = font.getbbox(text)\n",
    "    w, h = r-l,b-t\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    draw.rectangle((0, image.height - (1.6*num_lines)*(h), image.width, image.height), fill=TINT_COLOR+(OPACITY,))\n",
    "    draw.text((5, image.height - (1.6*num_lines)*(h)), text, fill=text_color, font=font)\n",
    "    image = pili.alpha_composite(image, overlay)\n",
    "    image = image.convert(\"RGB\") \n",
    "    fname = f.split(\".\")[0]\n",
    "    if fname[-1].isdigit():\n",
    "        a = fname[-1]\n",
    "        image.save(fname[:-1] + str(a+1) + \".png\")\n",
    "    else:\n",
    "        image.save(fname+\"1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yayan_Li = pili.open(\"image/poster/Yayan_Li.png\")\n",
    "Yayan_Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_f = \"image/poster/Yayan_Li.png\"\n",
    "\n",
    "Yayan_Li_des = \"Husband: Perceived as a loser, \\nhe sacrifices for the marriage and \\ncarries guilt regarding his son.\"\n",
    "text_rec(open_f,Yayan_Li_des,(255, 255, 255),(0, 0, 0),.25,english_font,24)\n",
    "\n",
    "Yayan_Li1 = pili.open(\"image/poster/Yayan_Li1.png\")\n",
    "print(Yayan_Li1.size)\n",
    "Yayan_Li1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b58764",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yuxin_Li = pili.open(\"image/poster/Yuxin_Li.png\")\n",
    "Yuxin_Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_f = \"image/poster/Yuxin_Li.png\"\n",
    "Yuxin_Li_des = \"Wife: A successful writer, \\nassertive and she  exhibits great\\n rationality.\"\n",
    "text_rec(open_f,Yuxin_Li_des,(255, 255, 255),(0, 0, 0),.25,english_font,24)\n",
    "\n",
    "Yuxin_Li1 = pili.open(\"image/poster/Yuxin_Li1.png\")\n",
    "print(Yuxin_Li1.size)\n",
    "Yuxin_Li1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jihui_Sheng = pili.open(\"image/poster/Jihui_Sheng.png\")\n",
    "Jihui_Sheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_f = \"image/poster/Jihui_Sheng.png\"\n",
    "Jihui_Sheng_des = \"Child: Blind, the result of indirect\\n consequences caused by the \\nhusband.\"\n",
    "text_rec(open_f,Jihui_Sheng_des,(255, 255, 255),(0, 0, 0),.25,english_font,24)\n",
    "\n",
    "Jihui_Sheng1 = pili.open(\"image/poster/Jihui_Sheng1.png\")\n",
    "print(Jihui_Sheng1.size)\n",
    "Jihui_Sheng1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LiHsin_Fu = pili.open(\"image/poster/Li-Hsin_Fu.png\")\n",
    "LiHsin_Fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3eb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_f = \"image/poster/Li-Hsin_Fu.png\"\n",
    "LiHsin_Fu_des = \"Someone else\"\n",
    "text_rec(open_f,LiHsin_Fu_des,(255, 255, 255),(0, 0, 0),.25,english_font,24)\n",
    "\n",
    "LiHsin_Fu1 = pili.open(\"image/poster/Li-Hsin_Fu1.png\")\n",
    "print(LiHsin_Fu1.size)\n",
    "LiHsin_Fu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84757e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "list_im = ['image/poster/Li-Hsin_Fu1.png',\n",
    "            'image/poster/Yayan_Li1.png',\n",
    "            'image/poster/Yuxin_Li1.png',\n",
    "            'image/poster/Jihui_Sheng1.png']\n",
    "\n",
    "imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "min_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9952c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fst_row_comb = np.hstack( [np.asarray( i.resize(min_shape) ) for i in imgs[:2] ] )\n",
    "scd_row_comb = np.hstack( [np.asarray( i.resize(min_shape) ) for i in imgs[2:] ] )\n",
    "imgs_comb = np.vstack([i for i in [fst_row_comb,scd_row_comb]])\n",
    "imgs_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b50f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "imgs_comb.save( 'image/result/Actor.png' )    \n",
    "imgs_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd9bfa",
   "metadata": {},
   "source": [
    "## Scene 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98280a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify your column names\n",
    "captions = pd.read_csv(\"caption/scene1.csv\", names=['Caption'])\n",
    "print(captions.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_item = {'EN': '', 'CN': ''}\n",
    "caption_dic = []\n",
    "index = 0\n",
    "\n",
    "for _, row in captions.iterrows():\n",
    "#     print(row['Caption'])\n",
    "    if index == 2:\n",
    "        index = 0\n",
    "        caption_dic.append(caption_item.copy())  # Use copy to avoid overwriting the same dictionary\n",
    "        caption_item = {'EN': '', 'CN': ''}\n",
    "    if index == 0:\n",
    "        caption_item['CN'] = row['Caption']\n",
    "#         print(caption_item['CN'])\n",
    "        index += 1\n",
    "    elif index == 1:\n",
    "        caption_item['EN'] = row['Caption']\n",
    "#         print(caption_item['EN'])\n",
    "        index += 1\n",
    "if caption_item['EN'] != '' or caption_item['CN'] != '':\n",
    "    caption_dic.append(caption_item)\n",
    "for line in caption_dic:\n",
    "    print(line)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img,border=(100,100),fill=\"black\")\n",
    "    caption = lines;\n",
    "    TINT_COLOR = (255, 255, 255)\n",
    "    TRANSPARENCY = 0.2\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "    img = img.convert('RGBA')\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR + (0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"Roboto-Regular.ttf\", 40)\n",
    "    text = caption\n",
    "\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    x, y = 100, img.height - (num_lines - 0.5 * num_lines) * text_height\n",
    "\n",
    "    draw.rectangle((x, y, x + img.width - 200, y + (num_lines - 0.1 * num_lines) * text_height), fill=TINT_COLOR + (OPACITY,))\n",
    "    draw.text((x, y), text, fill=(209, 239, 8), font=font)\n",
    "\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e440f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:# adding border and Chinese caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap_cn(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img,border=(100,100),fill=\"black\")\n",
    "    caption = lines;\n",
    "    TINT_COLOR = (255, 255, 255)\n",
    "    TRANSPARENCY = 0.2\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "    img = img.convert('RGBA')\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR + (0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"CN-Regular.ttf\", 40)\n",
    "    text = caption\n",
    "    # getting textarea width and height\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    x, y = 100, img.height - (num_lines - 0.004 * num_lines) * text_height\n",
    "\n",
    "    draw.rectangle((x, y, x + img.width - 200, y + (num_lines - 0.1 * num_lines) * text_height), fill=TINT_COLOR + (OPACITY,))\n",
    "    draw.text((x, y), text, fill=(209, 239, 8), font=font)\n",
    "\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:adding anime action\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from IPython.display import display\n",
    "def imgcompress_mem(path_in, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:adding anime action\n",
    "\n",
    "def cartoonizebl_mem(path_in, k, blur, line):\n",
    "    \n",
    "    imgc = imgcompress_mem(path_in, k)\n",
    "    #imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(imgc_pil))\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    #imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    bigedges_pil = cv2.cvtColor(bigedges, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(bigedges_pil))\n",
    "\n",
    "    return cv2.bitwise_and(imgc, imgc, mask=bigedges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_in = 'movie_pic/test.png'\n",
    "def anime(path_in):\n",
    "    cblimg = cartoonizebl_mem(path_in, 2, 3, 5)\n",
    "    cblimg_pil = cv2.cvtColor(cblimg, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    return Image.fromarray(cblimg_pil)\n",
    "# anime(path_in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "# adding anime-EN\n",
    "# Specify the directory\n",
    "# image_directory = \"output_images\"\n",
    "image_directory = \"image/scene1/movie_pic\"\n",
    "\n",
    "# Create a directory to store the saved images\n",
    "output_directory = \"image/scene1/anime\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each file\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        image = anime(image_path)\n",
    "        output_path = os.path.join(output_directory, filename)\n",
    "        image.save(output_path)\n",
    "# Optional: Display a message indicating the process is complete\n",
    "print(\"Images saved to:\", output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1860e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# adding anime-CN\n",
    "# Specify the directory\n",
    "# image_directory = \"output_images_cn\"\n",
    "image_directory = \"image/scene1/movie_pic\"\n",
    "\n",
    "# Create a directory to store the saved images\n",
    "output_directory = \"image/scene1/cn_anime\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each file\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        image = anime(image_path)\n",
    "        output_path = os.path.join(output_directory, filename)\n",
    "        image.save(output_path)\n",
    "# Optional: Display a message indicating the process is complete\n",
    "print(\"Images saved to:\", output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding margin and English caption\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "image_directory = \"image/scene1/anime\"\n",
    "\n",
    "# Create a directory to store the saved images\n",
    "output_directory = \"image/scene1/output_images\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each file\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "#         image = Image.open(image_path)\n",
    "        \n",
    "        index = int(filename.split('.')[0])\n",
    "        if 0 < index <= len(caption_dic):\n",
    "#             print(index)\n",
    "            caption = caption_dic[index-1]['EN']\n",
    "            image = img_frame_cap(image_path,caption)\n",
    "#             image = anime(image_path)\n",
    "            # Save the image to the output directory\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "            image.save(output_path)\n",
    "# Optional: Display a message indicating the process is complete\n",
    "print(\"Images saved to:\", output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60314c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding margin and Chinese caption\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "image_directory = \"image/scene1/cn_anime\"\n",
    "\n",
    "# Create a directory to store the saved images\n",
    "output_directory = \"image/scene1/output_images_cn\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each file\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "#         image = Image.open(image_path)\n",
    "        \n",
    "        index = int(filename.split('.')[0])\n",
    "        if 0 < index <= len(caption_dic):\n",
    "            caption = caption_dic[index-1]['CN']\n",
    "            image = img_frame_cap_cn(image_path,caption)\n",
    "#             image = anime(image_path)\n",
    "            # Save the image to the output directory\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "            image.save(output_path)\n",
    "# Optional: Display a message indicating the process is complete\n",
    "print(\"Images saved to:\", output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Folder path\n",
    "folder_path = 'image/scene1/output_images'\n",
    "folder_path2 = 'image/scene1/output_images_cn'\n",
    "\n",
    "# Load all images and resize them to the same size\n",
    "def load_and_resize_images(folder_path, target_size):\n",
    "    images = []\n",
    "#     get list of image filenames sorted by name\n",
    "    filenames = sorted([filename for filename in os.listdir(folder_path) if filename.endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "# Concatenate images\n",
    "def concat_images(images, num_rows, num_cols):\n",
    "    img_width, img_height = images[0].size\n",
    "    canvas_width = img_width * num_cols\n",
    "    canvas_height = img_height * num_rows\n",
    "    canvas = Image.new('RGB', (canvas_width, canvas_height), color='white')\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < len(images):\n",
    "                img = images[index]\n",
    "                canvas.paste(img, (j * img_width, i * img_height))\n",
    "    return canvas\n",
    "\n",
    "# Target image size\n",
    "target_size = (250, 250)  # Replace with the desired image size\n",
    "# Image arrangement\n",
    "num_rows = 5\n",
    "num_cols = 4\n",
    "\n",
    "# Load and resize\n",
    "images = load_and_resize_images(folder_path, target_size)\n",
    "\n",
    "# Concatenate images\n",
    "concatenated_image = concat_images(images, num_rows, num_cols)\n",
    "\n",
    "# Save the concatenated image\n",
    "concatenated_image.save('image/result/scene1_eng.jpg')\n",
    "Image.open('image/result/scene1_eng.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba72158",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_and_resize_images(folder_path2, target_size)\n",
    "\n",
    "# Concatenate images\n",
    "concatenated_image = concat_images(images, num_rows, num_cols)\n",
    "\n",
    "# Save the concatenated image\n",
    "concatenated_image.save('image/result/scene1_chn.jpg')\n",
    "Image.open('image/result/scene1_chn.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a604d41",
   "metadata": {},
   "source": [
    "## Scene 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_mid_text(img_path,text_str, font_path, font_size, text_color, height):\n",
    "    img = pili.open(img_path)\n",
    "    img = img.resize((400,300))\n",
    "    draw = pilid.Draw(img)\n",
    "    font = pilf.truetype(font_path,font_size)\n",
    "    bl,bt,br,bb = font.getbbox(text_str)\n",
    "    bw = br-bl\n",
    "    # print(bw)\n",
    "    text_pos = ((img.width - bw)//2,int(img.height*height))\n",
    "    # print(text_pos)\n",
    "    draw.text(text_pos,text_str,font=font,fill=text_color)\n",
    "    fname = img_path.split(\".\")[0]\n",
    "    if fname[-1].isdigit():\n",
    "        a = fname[-1]\n",
    "        img.save(fname[:-1] + str(int(a)+1) + \".png\")\n",
    "    else:\n",
    "        img.save(fname+\"1.png\")\n",
    "scene_mid_text(\"HW5_image/father.png\",\"english\",english_font,30,(255,255,255),0.78)\n",
    "scene_mid_text(\"HW5_image/father1.png\",u\"中文\",chinese_font,20,(255,255,255),0.9)\n",
    "f = pili.open(\"HW5_image/father2.png\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fpdf import FPDF\n",
    "from PIL import Image as pili, ImageDraw as pild, ImageFont as pilf, ImageOps as piliops\n",
    "\n",
    "TINT_COLOR = (0, 0, 0)  # Black\n",
    "OPACITY = int(255 * .50)\n",
    "FONT = pilf.truetype(english_font, 24) # Font\n",
    "IMG_BASE_WIDTH = 600\n",
    "IMG_NUMBERS = 47\n",
    "def convert_from_cv2_to_image(img: np.ndarray) -> pili:\n",
    "    return pili.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    #return pili.fromarray(img)\n",
    "\n",
    "def convert_from_image_to_cv2(img: pili) -> np.ndarray:\n",
    "    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    #return np.asarray(img)\n",
    "\n",
    "def imgcompress_mem(path_in, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "# Controls blur amount and line size and number of text lines. No bold font!\n",
    "def cartoonizeblt_mem_nb(path_in, k, blur, line, text, nlines=1, font='verdana'):\n",
    "    \n",
    "    # print(path_in)\n",
    "    imgc = imgcompress_mem(path_in, k)\n",
    "    \n",
    "    # resize\n",
    "    heighto = int(imgc.shape[0])\n",
    "    widtho = int(imgc.shape[1])\n",
    "    width = 300\n",
    "    height = int(heighto / widtho * width)\n",
    "    imgc = cv2.resize(imgc, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    bigedges_pil = cv2.cvtColor(bigedges, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "\n",
    "    toon = cv2.bitwise_and(imgc, imgc, mask=bigedges)\n",
    "    if 0 == len(text):\n",
    "        return toon\n",
    "    \n",
    "    # print('Using font ' + font + '...')\n",
    "    myfont = (\n",
    "        pilf.truetype(\"ITCKRIST.TTF\", \n",
    "            24 if k == 16 else 18 if k == 14 else 18 if k == 12 else 20 if k == 8 else 82) if font=='ITCKRIST'\n",
    "        else\n",
    "            pilf.truetype(\"Inkfree.ttf\", \n",
    "                24 if k == 16 else 18 if k == 14 else 18 if k == 12 else 20 if k == 8 else 82) if font=='Inkfree'\n",
    "        else\n",
    "            pilf.truetype(font + \".ttf\", 24 if k == 16 else 18 if k == 14 else 18 if k == 12 else 20 if k == 8 else 82)\n",
    "    )\n",
    "\n",
    "\n",
    "    cblimg_pil = pili.fromarray(cv2.cvtColor(toon, cv2.COLOR_BGR2RGBA))\n",
    "\n",
    "    overlay = pili.new('RGBA', cblimg_pil.size, TINT_COLOR+(0,))\n",
    "    draw = pilid.Draw(overlay)\n",
    "    #_, h = FONT.getsize(text)\n",
    "    l,t,r,b = myfont.getbbox(text)\n",
    "    w,h = r-l,b-t\n",
    "    # _, h = myfont.getsize(text)\n",
    "    # num_lines = nlines\n",
    "    lines = []\n",
    "    line = []\n",
    "    words = text.split()\n",
    "    # fpr each word in sentence\n",
    "    for word in words:\n",
    "        # add word get length\n",
    "        ll,lt,lr,lb = myfont.getbbox(' '.join(line + [word]))\n",
    "        lw = lr - ll\n",
    "        # if exceed\n",
    "        if line and lw > width*0.8:\n",
    "            # add one line\n",
    "            lines.append(' '.join(line))\n",
    "            # line init new word\n",
    "            line = [word]\n",
    "        else:\n",
    "            # else add word\n",
    "            line.append(word)\n",
    "    # add last line\n",
    "    lines.append(' '.join(line))\n",
    "    # print(lines)\n",
    "    num_lines = len(lines)\n",
    "    # x, y = 0, cblimg_pil.height - h-20\n",
    "    x,y = 0,cblimg_pil.height-(num_lines)*h\n",
    "    # print(x,y)\n",
    "    draw.rectangle((x, y-10, x + cblimg_pil.width, y + (num_lines)*h+30), fill=TINT_COLOR+(OPACITY,))\n",
    "    for i in range(num_lines):\n",
    "        if k == 1:\n",
    "            draw.text((x+10, y + h*(i)-10), lines[i], fill=(248,248,248), font=myfont) #, stroke_width=1)\n",
    "        elif k < 8:\n",
    "            draw.text((x+10, y + h*(i)-10), lines[i], fill=(248,248,248), font=myfont)\n",
    "        else:\n",
    "            draw.text((x+10, y + h*(i)-10), lines[i], fill=(248,248,248), font=myfont) #, stroke_width=1)\n",
    "\n",
    "    cblimg_pil = pili.alpha_composite(cblimg_pil, overlay)\n",
    "    cblimg_pil = cblimg_pil.convert(\"RGB\")\n",
    "\n",
    "    return convert_from_image_to_cv2(cblimg_pil)\n",
    "    \n",
    "def simple_row(folder, list_im, list_opt, list_txt, list_nlines, font='arial'):\n",
    "    \n",
    "    # cartoonize them in memory with text\n",
    "    cimgs = [ cartoonizeblt_mem_nb(folder + '/p' + i + '.jpg', 14, 3, 3, k, nlines=n, font=font)\n",
    "              for i,j,k,n in zip(list_im, list_opt, list_txt, list_nlines) ]\n",
    "    # print(cimgs)\n",
    "    # resize\n",
    "    heighto = int(cimgs[0].shape[0])\n",
    "    widtho = int(cimgs[0].shape[1])\n",
    "    # heighto / widtho = height / width ==> height = heighto / widtho * width\n",
    "    width = 245\n",
    "    height = int(heighto / widtho * width)\n",
    "    cimgs_dim = (width, height)\n",
    "    cimgsr = [ cv2.resize(cimgs[i], cimgs_dim, interpolation = cv2.INTER_AREA) for i in range(20)]\n",
    "\n",
    "    # add borders\n",
    "    white = [255,255,255]\n",
    "    bcimgs = [ cv2.copyMakeBorder(i, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=white) for i in cimgsr ]\n",
    "    for i in range(len(bcimgs)):\n",
    "        cv2.imwrite(folder + \"/imgs/p\" + str(i) + \".jpg\", i)\n",
    "    # stack them horizontally\n",
    "    return np.concatenate([ bcimgs[i] for i in range(0,len(list_im)) ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rows(folder, list_im, list_opt, list_txt, list_nlines, font='arial'):\n",
    "    \n",
    "    # cartoonize them in memory with text\n",
    "    cimgs = [ cartoonizeblt_mem_nb(folder + '/p' + i + '.jpg', 14, 3, 3, k, nlines=n, font=font)\n",
    "              for i,j,k,n in zip(list_im, list_opt, list_txt, list_nlines) ]\n",
    "\n",
    "    # if not resize again, it will has size error\n",
    "    heighto = int(cimgs[0].shape[0])\n",
    "    widtho = int(cimgs[0].shape[1])\n",
    "    # heighto / widtho = height / width ==> height = heighto / widtho * width\n",
    "    width = 250\n",
    "    height = 200\n",
    "    cimgs_dim = (width, height)\n",
    "    cimgsr = [ cv2.resize(cimgs[i], cimgs_dim, interpolation = cv2.INTER_AREA) for i in range(20)]\n",
    "\n",
    "    # add borders\n",
    "    white = [255,255,255]\n",
    "    bcimgs = [ cv2.copyMakeBorder(i, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=white) for i in cimgsr ]\n",
    "    rows = []\n",
    "\n",
    "    # random img each row\n",
    "    # images_per_row = np.random.randint(3, 6)\n",
    "    images_per_row = 4\n",
    "    r = 0\n",
    "    # for each row\n",
    "    while r < len(bcimgs):\n",
    "        row_imgs = bcimgs[r:r+images_per_row]\n",
    "        if row_imgs:\n",
    "            row_combined = np.concatenate(row_imgs, axis=1)\n",
    "            rows.append(row_combined)\n",
    "        r+= images_per_row\n",
    "        # images_per_row = np.random.randint(3, 6)\n",
    "    if rows:\n",
    "        final_layout = np.concatenate(rows, axis=0)\n",
    "    else:\n",
    "        final_layout = np.array([])\n",
    "    \n",
    "    return final_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# file path\n",
    "xlsx_path = 'caption/scene2.xlsx'\n",
    "\n",
    "df = pd.read_excel(xlsx_path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = df['English'].tolist()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc36ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows4 = simple_row (\n",
    "        'image/scene2/movie_pic', \n",
    "         [str(i) for i in range(len(lines))],\n",
    "         [i for i in range(len(lines))],\n",
    "         lines,\n",
    "         [1 for i in range(len(lines))]\n",
    "        )\n",
    "rows4_pil = cv2.cvtColor(rows4, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "display(pili.fromarray(rows4_pil))\n",
    "# rows4_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows4 = multi_rows (\n",
    "        'image/scene2/movie_pic', \n",
    "         [str(i) for i in range(len(lines))],\n",
    "         [i for i in range(len(lines))],\n",
    "         lines,\n",
    "         [1 for i in range(len(lines))]\n",
    "        )\n",
    "rows4_pil = cv2.cvtColor(rows4, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "display(pili.fromarray(rows4_pil))\n",
    "cv2.imwrite(\"image/result/scene2.jpg\",rows4)\n",
    "# rows4_pil\n",
    "# rows4_pil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_ch = df['Chinese'].tolist()\n",
    "lines_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows4 = multi_rows (\n",
    "        'image/scene2/movie_pic', \n",
    "         [str(i) for i in range(len(lines_ch))],\n",
    "         [i for i in range(len(lines_ch))],\n",
    "         lines_ch,\n",
    "         [1 for i in range(len(lines_ch))],\n",
    "        font=chinese_font.split(\".\")[0]\n",
    "        )\n",
    "rows4_pil = cv2.cvtColor(rows4, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "display(pili.fromarray(rows4_pil))\n",
    "cv2.imwrite(\"image/result/scene2_ch.jpg\",rows4)\n",
    "# rows4_pil\n",
    "# rows4_pil.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06732",
   "metadata": {},
   "source": [
    "## Scene 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f330dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:border+caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img,border=(100,100),fill=\"black\")\n",
    "    caption = lines;\n",
    "    # TINT_COLOR = (255, 255, 255)\n",
    "    TINT_COLOR = (0, 0, 0)\n",
    "    TRANSPARENCY = 0.3\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "    img = img.convert('RGBA')\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR + (0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"Roboto-Regular.ttf\", 30)\n",
    "    text = caption\n",
    "    # Calculate the x, y coordinates for center-top placement\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    # text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "    text_height = 30\n",
    "    \n",
    "    num_lines = len(text.split('\\n'))\n",
    "    x, y = 100, img.height - (num_lines - 0.01 * num_lines) * text_height\n",
    "\n",
    "    draw.rectangle((x, y, x + img.width - 200, y + (num_lines - 0.01 * num_lines) * text_height), fill=TINT_COLOR + (OPACITY,))\n",
    "    draw.text((x, y), text, fill=(209, 239, 8), font=font)\n",
    "\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:border+caption-CN\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap2(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img,border=(100,100),fill=\"black\")\n",
    "    caption = lines;\n",
    "    # TINT_COLOR = (255, 255, 255)\n",
    "    TINT_COLOR = (0, 0, 0)\n",
    "    TRANSPARENCY = 0.3\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "    img = img.convert('RGBA')\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR + (0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"CN-Regular.ttf\", 30)\n",
    "    text = caption\n",
    "    # Calculate the x, y coordinates for center-top placement\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    # text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "    text_height = 30\n",
    "    \n",
    "    num_lines = len(text.split('\\n'))\n",
    "    x, y = 100, img.height - (num_lines - 0.01 * num_lines) * text_height\n",
    "\n",
    "    draw.rectangle((x, y, x + img.width - 200, y + (num_lines - 0.01 * num_lines) * text_height), fill=TINT_COLOR + (OPACITY,))\n",
    "    draw.text((x, y), text, fill=(209, 239, 8), font=font)\n",
    "\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:adding anime action\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from IPython.display import display\n",
    "def imgcompress_mem(path_in, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgcompress(path_in, path_out, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    scaled = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # get the resized image output by imwrite() function of openCV library\n",
    "    cv2.imwrite(path_out, scaled)\n",
    "    \n",
    "    # display result\n",
    "    imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    display(Image.fromarray(imgc_pil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:adding anime action\n",
    "\n",
    "def cartoonizebl_mem(path_in, k, blur, line):\n",
    "    \n",
    "    imgc = imgcompress_mem(path_in, k)\n",
    "    #imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(imgc_pil))\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    #imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    bigedges_pil = cv2.cvtColor(bigedges, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(bigedges_pil))\n",
    "\n",
    "    return cv2.bitwise_and(imgc, imgc, mask=bigedges)\n",
    "\n",
    "# processing : adding anime action\n",
    "\n",
    "import cv2 \n",
    "\n",
    "def cartoonizebl_mem(img, k, blur, line):\n",
    "    imgc = imgcompress_mem(img, k)\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    \n",
    "    return cv2.bitwise_and(imgc, imgc, mask=bigedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "captions = pd.read_csv(\"caption/scene3.csv\")\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime(path_in, path_out):\n",
    "    cblimg = cartoonizebl_mem(path_in, 2, 3, 5)\n",
    "    cblimg_pil = cv2.cvtColor(cblimg, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    # display(Image.fromarray(cblimg_pil))\n",
    "    \n",
    "    width = int(cblimg_pil.shape[1])\n",
    "    height = int(cblimg_pil.shape[0])\n",
    "    \n",
    "    scaled = cv2.resize(cblimg, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite(path_out, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436caeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene3/scene3_pic/'\n",
    "out_folder_path = 'image/scene3/scene3_pic_captionE/'\n",
    "pics = [\"judge\", \n",
    "        \"ryan1\", \n",
    "        \"prosecutor1\", \n",
    "        \"ryan2\", \n",
    "        \"lawyer\", \n",
    "        \"ryan3\", \n",
    "        \"prosecutor2\", \n",
    "        \"ryan2\", \n",
    "        \"ryan3\", \n",
    "        \"max\",\n",
    "        \"prosecutor3\", \n",
    "        \"ryan2\", \n",
    "        \"judge\", \n",
    "        \"ryan3\", \n",
    "        \"court\",\n",
    "        \"prosecutor4\",\n",
    "        \"prosecutor1\",\n",
    "        \"prosecutor2\",\n",
    "        \"ryan1\",\n",
    "        \"court\"\n",
    "       ]\n",
    "index = 0\n",
    "for n, i in enumerate(pics):\n",
    "    \n",
    "    input_path = join(folder_path, f'{i}.png')\n",
    "    anime_output_path = join(folder_path, f'{i}_anime.png')\n",
    "    final_output_path = join(out_folder_path, f'{n}_{i}_with_caption_E.png')\n",
    "    \n",
    "    anime(input_path, anime_output_path)\n",
    "    \n",
    "    caption_text = captions[\"English\"][index]\n",
    "    index += 1\n",
    "    img_frame_cap(anime_output_path, caption_text).save(final_output_path)\n",
    "    \n",
    "    print(f'Processed image {i}: {final_output_path}')\n",
    "    display(Image.open(final_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'image/scene3/scene3_pic/'\n",
    "out_folder_path = 'image/scene3/scene3_pic_captionC/'\n",
    "index = 0\n",
    "for n, i in enumerate(pics):\n",
    "    \n",
    "    input_path = join(folder_path, f'{i}.png')\n",
    "    anime_output_path = join(folder_path, f'{i}_anime.png')\n",
    "    final_output_path = join(out_folder_path, f'{n}_{i}_with_caption_C.png')\n",
    "    \n",
    "    # anime(input_path, anime_output_path)\n",
    "    \n",
    "    caption_text = captions[\"Chinese\"][index]\n",
    "    index += 1\n",
    "    img_frame_cap2(anime_output_path, caption_text).save(final_output_path, format='PNG')\n",
    "    \n",
    "    print(f'Processed image {i}: {final_output_path}')\n",
    "    display(Image.open(final_output_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "mypath = 'image/scene3/scene3_pic_captionE/'\n",
    "\n",
    "def custom_key(item):\n",
    "    index = 0\n",
    "    for i in range(len(item)):\n",
    "        if item[i] == '_':\n",
    "            index = i\n",
    "            break\n",
    "    return int(item[:index])\n",
    "    \n",
    "onlyfiles = sorted([f for f in listdir(mypath) if isfile(join(mypath, f))], key=custom_key)\n",
    "\n",
    "cols = [0, 4, 5, 6, 5]\n",
    "img_cols = []\n",
    "\n",
    "lines = 0\n",
    "print(\"new page!\")\n",
    "num_cols = old_num_cols = 0\n",
    "while lines < 4 and 0 < len(onlyfiles):\n",
    "    lines += 1\n",
    "    while num_cols == old_num_cols:\n",
    "        num_cols = cols[lines]\n",
    "    old_num_cols = num_cols\n",
    "    window = onlyfiles[:num_cols]\n",
    "    img_cols.append(window)\n",
    "    print(window)   \n",
    "    onlyfiles = onlyfiles[num_cols:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "def horizontal_strip(list_im, path_in, path_out):\n",
    "    imgs = [ PIL.Image.open(join(path_in, i)) for i in list_im ]\n",
    "    \n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.hstack( [np.asarray( i.resize(min_shape) ) for i in imgs ] )\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save( path_out, format='PNG' )\n",
    "    # display(Image.open(path_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip each col of the imgs\n",
    "mypathin = 'image/scene3/scene3_pic_captionE/'\n",
    "mypathout = 'image/scene3/scene3_pic/'\n",
    "for i, list in enumerate(img_cols):\n",
    "    horizontal_strip(list, mypathin, join(mypathout, f'col_{i}_e.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip all the cols together\n",
    "list_im = [join(mypathout, f'col_{i}_e.png') for i in range(4)]\n",
    "imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "imgs_comb = np.vstack( [np.asarray( i.resize(min_shape) ) for i in imgs ] ) ##\n",
    "\n",
    "# save that beautiful picture\n",
    "imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "imgs_comb.save( 'image/result/scene3_E.png', format='PNG' ) \n",
    "# display(Image.open(join(mypathout, 'scene3_E.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed73f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'image/scene3/scene3_pic_captionC/'\n",
    "\n",
    "def custom_key(item):\n",
    "    index = 0\n",
    "    for i in range(len(item)):\n",
    "        if item[i] == '_':\n",
    "            index = i\n",
    "            break\n",
    "    return int(item[:index])\n",
    "    \n",
    "onlyfiles = sorted([f for f in listdir(mypath) if isfile(join(mypath, f))], key=custom_key)\n",
    "\n",
    "cols = [0, 4, 5, 6, 5]\n",
    "img_cols = []\n",
    "\n",
    "lines = 0\n",
    "print(\"new page!\")\n",
    "num_cols = old_num_cols = 0\n",
    "while lines < 4 and 0 < len(onlyfiles):\n",
    "    lines += 1\n",
    "    while num_cols == old_num_cols:\n",
    "        num_cols = cols[lines]\n",
    "    old_num_cols = num_cols\n",
    "    window = onlyfiles[:num_cols]\n",
    "    img_cols.append(window)\n",
    "    print(window)   \n",
    "    onlyfiles = onlyfiles[num_cols:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypathin = 'image/scene3/scene3_pic_captionC/'\n",
    "mypathout = 'image/result/'\n",
    "for i, list in enumerate(img_cols):\n",
    "    horizontal_strip(list, mypathin, join(mypathout, f'col_{i}_c.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_im = [join(mypathout, f'col_{i}_c.png') for i in range(4)]\n",
    "imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "imgs_comb = np.vstack( [np.asarray( i.resize(min_shape) ) for i in imgs ] ) ##\n",
    "\n",
    "# save that beautiful picture\n",
    "imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "imgs_comb.save( join(mypathout, 'scene3_C.png'), format='PNG' ) \n",
    "# display(Image.open(join(mypathout, 'scene3_C.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647f8b7",
   "metadata": {},
   "source": [
    "## Scene 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10247042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "caption = pd.read_csv('caption/scene4.csv', header = None)\n",
    "scene4_caption_Chinese = caption[0:20]\n",
    "scene4_caption_English = caption[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap1(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"Roboto-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the maximum width for the caption (80% of the image width)\n",
    "    max_caption_width = int(img.width * 0.7)\n",
    "\n",
    "    # Function to split the caption into multiple lines if it exceeds the max width\n",
    "    def split_text(caption):\n",
    "        lines = []\n",
    "        words = caption.split(' ')\n",
    "        current_line = words[0]\n",
    "\n",
    "        for word in words[1:]:\n",
    "            test_line = current_line + ' ' + word\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "            if text_width <= max_caption_width:\n",
    "                current_line = test_line\n",
    "            else:\n",
    "                lines.append(current_line)\n",
    "                current_line = word\n",
    "\n",
    "        lines.append(current_line)\n",
    "        return lines\n",
    "\n",
    "    # Split the caption into multiple lines if needed\n",
    "    caption_lines = split_text(caption)\n",
    "\n",
    "    # Calculate the total height required for the caption\n",
    "    total_text_height = len(caption_lines) * font_size\n",
    "\n",
    "\n",
    "    # Calculate the y-coordinate for placement (1/6th from the bottom)\n",
    "    y = img.height // 8  # One-third from the top\n",
    "\n",
    "\n",
    "    # Draw each line of the caption\n",
    "    for line in caption_lines:\n",
    "        # Calculate the bounding box for each line\n",
    "        text_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "        # Calculate the x-coordinate for centering each line\n",
    "        x = (img.width - text_width) // 2  # Center horizontally\n",
    "        \n",
    "        draw.text((x, y), line, fill=(0, 0, 0), font=font)\n",
    "        y += font_size  # Move to the next line\n",
    "\n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap2(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"Roboto-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the maximum width for the caption (80% of the image width)\n",
    "    max_caption_width = int(img.width * 0.7)\n",
    "\n",
    "    # Function to split the caption into multiple lines if it exceeds the max width\n",
    "    def split_text(caption):\n",
    "        lines = []\n",
    "        words = caption.split(' ')\n",
    "        current_line = words[0]\n",
    "\n",
    "        for word in words[1:]:\n",
    "            test_line = current_line + ' ' + word\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "            if text_width <= max_caption_width:\n",
    "                current_line = test_line\n",
    "            else:\n",
    "                lines.append(current_line)\n",
    "                current_line = word\n",
    "\n",
    "        lines.append(current_line)\n",
    "        return lines\n",
    "\n",
    "    # Split the caption into multiple lines if needed\n",
    "    caption_lines = split_text(caption)\n",
    "\n",
    "    # Calculate the total height required for the caption\n",
    "    total_text_height = len(caption_lines) * font_size\n",
    "\n",
    "\n",
    "    # Calculate the y-coordinate for placement (1/6th from the bottom)\n",
    "    y = img.height - img.height // 6 - total_text_height // 2\n",
    "\n",
    "\n",
    "    # Draw each line of the caption\n",
    "    for line in caption_lines:\n",
    "        # Calculate the bounding box for each line\n",
    "        text_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "        # Calculate the x-coordinate for centering each line\n",
    "        x = (img.width - text_width) // 2  # Center horizontally\n",
    "        \n",
    "        # Draw a filled black rectangle as the background for the text\n",
    "        draw.rectangle([x, y, x + text_width, y + font_size], fill=\"black\")\n",
    "\n",
    "        draw.text((x, y), line, fill=(255, 255, 8), font=font)\n",
    "        y += font_size  # Move to the next line\n",
    "\n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap3(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"Roboto-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the x, y coordinates for center-bottom placement\n",
    "    text_bbox = draw.textbbox((0, 0), caption, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "\n",
    "    x = (img.width - text_width) // 2  # Center horizontally\n",
    "    y = img.height - 100 - text_height  # 100 pixels from the bottom\n",
    "\n",
    "    draw.text((x, y), caption, fill=(255, 255, 0), font=font)\n",
    "    \n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : adding anime action\n",
    "\n",
    "import cv2 \n",
    "\n",
    "def cartoonizebl_mem(img, k, blur, line):\n",
    "    imgc = imgcompress_mem(img, k)\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    \n",
    "    return cv2.bitwise_and(imgc, imgc, mask=bigedges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgcompress_mem(img, k):\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e903fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime(path_in, save_path, target_size=(4000, 3000)):\n",
    "    # Load the image\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Apply cartoonize effect\n",
    "    cblimg = cartoonizebl_mem(img_resized, 2, 3, 5)\n",
    "\n",
    "    # Convert NumPy array to PIL Image\n",
    "    cblimg_pil = Image.fromarray(cv2.cvtColor(cblimg, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Save the anime action image without displaying\n",
    "    cblimg_pil.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb794915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "path_in = 'image/scene4/movie_pic/pic1.png'\n",
    "save_path = 'image/scene4/anime/pic1_anime.png'\n",
    "anime(path_in, save_path)\n",
    "\n",
    "caption = scene4_caption_English.values[0][0]\n",
    "img_frame_cap1('image/scene4/anime/pic1_anime.png', caption).save('image/scene4/eng/pic1_with_caption.png')\n",
    "\n",
    "# Display the image with caption\n",
    "display(Image.open('image/scene4/eng/pic1_with_caption.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb005e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/movie_pic/'\n",
    "anime_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/eng/'\n",
    "loop_pic_index = [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    input_path = join(folder_path, f'pic{i}.png')\n",
    "    anime_output_path = join(anime_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption.png')\n",
    "    \n",
    "    anime(input_path, anime_output_path)\n",
    "    \n",
    "    caption_text = scene4_caption_English.values[i-1][0]\n",
    "    img_frame_cap1(anime_output_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47befc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/movie_pic/'\n",
    "anime_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/eng/'\n",
    "loop_pic_index = [5, 9, 16, 17]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    input_path = join(folder_path, f'pic{i}.png')\n",
    "    anime_output_path = join(anime_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption.png')\n",
    "    \n",
    "    anime(input_path, anime_output_path)\n",
    "    \n",
    "    caption_text = scene4_caption_English.values[i-1][0]\n",
    "    img_frame_cap2(anime_output_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/movie_pic/'\n",
    "anime_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/eng/'\n",
    "loop_pic_index = [19, 20]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    input_path = join(folder_path, f'pic{i}.png')\n",
    "    anime_output_path = join(anime_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption.png')\n",
    "    \n",
    "    anime(input_path, anime_output_path)\n",
    "    \n",
    "    caption_text = scene4_caption_English.values[i-1][0]\n",
    "    img_frame_cap3(anime_output_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7734a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "folder_path = 'image/scene4/eng'\n",
    "\n",
    "for i in range(1, 21):\n",
    "    image_path = join(folder_path, f'pic{i}_with_caption.png')\n",
    "    display(Image.open(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47760942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_path = 'image/scene4/eng'\n",
    "\n",
    "num_cols = 4  # You can adjust the number of columns for the final poster\n",
    "num_rows = 5\n",
    "# num_rows = int(np.ceil(len(onlyfiles) / num_cols))\n",
    "\n",
    "poster = Image.new('RGB', (num_cols * 2000, num_rows * 1500))\n",
    "\n",
    "for i in range(1, 21):\n",
    "    img = Image.open(join(folder_path, f'pic{i}_with_caption.png'))\n",
    "    col = (i-1) % num_cols\n",
    "    row = (i-1) // num_cols\n",
    "    poster.paste(img.resize((2000, 1500)), (col * 2000, row * 1500))\n",
    "\n",
    "# Save the poster to a file\n",
    "poster.save('image/result/scene4_eng.jpg')\n",
    "\n",
    "\n",
    "poster.show()  # Display the final poster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e049ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.open('image/result/scene4_eng.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd74d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import unicodedata\n",
    "\n",
    "def img_frame_cap1(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"CN-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the maximum width for the caption (80% of the image width)\n",
    "    max_caption_width = int(img.width * 0.7)\n",
    "\n",
    "    # Function to split the caption into multiple lines if it exceeds the max width\n",
    "    def split_text(caption, max_chars_per_line=12):\n",
    "        lines = []\n",
    "        current_line = \"\"\n",
    "\n",
    "        for char in caption:\n",
    "            char_width = unicodedata.east_asian_width(char)\n",
    "            if char_width in (\"W\", \"F\"):  # Wide or Full-width character\n",
    "                max_chars_per_line = 12  # Adjust as needed for your layout\n",
    "\n",
    "            current_line += char\n",
    "\n",
    "            if len(current_line) >= max_chars_per_line:\n",
    "                lines.append(current_line)\n",
    "                current_line = \"\"\n",
    "\n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "\n",
    "        return lines\n",
    "\n",
    "    # Split the caption into multiple lines if needed\n",
    "    caption_lines = split_text(caption)\n",
    "\n",
    "    # Calculate the total height required for the caption\n",
    "    total_text_height = len(caption_lines) * font_size\n",
    "\n",
    "\n",
    "    # Calculate the y-coordinate for placement (1/6th from the bottom)\n",
    "    y = img.height // 8  # One-third from the top\n",
    "\n",
    "\n",
    "    # Draw each line of the caption\n",
    "    for line in caption_lines:\n",
    "        # Calculate the bounding box for each line\n",
    "        text_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "        # Calculate the x-coordinate for centering each line\n",
    "        x = (img.width - text_width) // 2  # Center horizontally\n",
    "        \n",
    "        draw.text((x, y), line, fill=(0, 0, 0), font=font)\n",
    "        y += font_size  # Move to the next line\n",
    "\n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfeb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import unicodedata\n",
    "\n",
    "def img_frame_cap2(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"CN-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the maximum width for the caption (80% of the image width)\n",
    "    max_caption_width = int(img.width * 0.7)\n",
    "\n",
    "    # Function to split the caption into multiple lines if it exceeds the max width\n",
    "    def split_text(caption, max_chars_per_line=12):\n",
    "        lines = []\n",
    "        current_line = \"\"\n",
    "\n",
    "        for char in caption:\n",
    "            char_width = unicodedata.east_asian_width(char)\n",
    "            if char_width in (\"W\", \"F\"):  # Wide or Full-width character\n",
    "                max_chars_per_line = 12  # Adjust as needed for your layout\n",
    "\n",
    "            current_line += char\n",
    "\n",
    "            if len(current_line) >= max_chars_per_line:\n",
    "                lines.append(current_line)\n",
    "                current_line = \"\"\n",
    "\n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "\n",
    "        return lines\n",
    "\n",
    "\n",
    "\n",
    "    # Split the caption into multiple lines if needed\n",
    "    caption_lines = split_text(caption)\n",
    "\n",
    "    # Calculate the total height required for the caption\n",
    "    total_text_height = len(caption_lines) * font_size\n",
    "\n",
    "\n",
    "    # Calculate the y-coordinate for placement (1/6th from the bottom)\n",
    "    y = img.height - img.height // 6 - total_text_height // 2\n",
    "\n",
    "\n",
    "    # Draw each line of the caption\n",
    "    for line in caption_lines:\n",
    "        # Calculate the bounding box for each line\n",
    "        text_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "\n",
    "        # Calculate the x-coordinate for centering each line\n",
    "        x = (img.width - text_width) // 2  # Center horizontally\n",
    "        \n",
    "        # Draw a filled black rectangle as the background for the text\n",
    "        draw.rectangle([x, y, x + text_width, y + font_size], fill=\"black\")\n",
    "\n",
    "        draw.text((x, y), line, fill=(255, 255, 8), font=font)\n",
    "        y += font_size  # Move to the next line\n",
    "\n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68dcb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : border & caption\n",
    "from PIL import Image as pili, ImageOps as piliops,ImageDraw as pild, ImageFont as pilf\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "def img_frame_cap3(path_in, lines):\n",
    "    img = pili.open(path_in)\n",
    "    img = piliops.expand(img, border=(50, 50), fill=\"black\")\n",
    "    \n",
    "    # Add caption without affecting anime action\n",
    "    caption = lines\n",
    "    draw = pild.Draw(img)\n",
    "    font_size = 100\n",
    "    font = pilf.truetype(\"CN-Regular.ttf\", font_size)\n",
    "    \n",
    "    # Calculate the x, y coordinates for center-bottom placement\n",
    "    text_bbox = draw.textbbox((0, 0), caption, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]  # right - left\n",
    "    text_height = text_bbox[3] - text_bbox[1]  # bottom - top\n",
    "\n",
    "    x = (img.width - text_width) // 2  # Center horizontally\n",
    "    y = img.height - 100 - text_height  # 100 pixels from the bottom\n",
    "\n",
    "    draw.text((x, y), caption, fill=(255, 255, 0), font=font)\n",
    "    \n",
    "    # Convert the image color space from BGR to RGB\n",
    "    img = img.convert(\"RGB\")\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing : adding anime action\n",
    "\n",
    "import cv2 \n",
    "\n",
    "def cartoonizebl_mem(img, k, blur, line):\n",
    "    imgc = imgcompress_mem(img, k)\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    \n",
    "    return cv2.bitwise_and(imgc, imgc, mask=bigedges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff34ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgcompress_mem(img, k):\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7341af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime(path_in, save_path, target_size=(4000, 3000)):\n",
    "    # Load the image\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Apply cartoonize effect\n",
    "    cblimg = cartoonizebl_mem(img_resized, 2, 3, 5)\n",
    "\n",
    "    # Convert NumPy array to PIL Image\n",
    "    cblimg_pil = Image.fromarray(cv2.cvtColor(cblimg, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Save the anime action image without displaying\n",
    "    cblimg_pil.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/chi/'\n",
    "loop_pic_index = [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    anime_path = join(folder_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption_c.png')\n",
    "\n",
    "    caption_text = scene4_caption_Chinese.values[i-1][0]\n",
    "    img_frame_cap1(anime_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/chi/'\n",
    "loop_pic_index = [5, 9, 16, 17]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    anime_path = join(folder_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption_c.png')\n",
    "\n",
    "    caption_text = scene4_caption_Chinese.values[i-1][0]\n",
    "    img_frame_cap2(anime_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87deb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "folder_path = 'image/scene4/anime/'\n",
    "output_path = 'image/scene4/chi/'\n",
    "loop_pic_index = [19, 20]\n",
    "\n",
    "for i in loop_pic_index:\n",
    "    \n",
    "    anime_path = join(folder_path, f'pic{i}_anime.png')\n",
    "    final_output_path = join(output_path, f'pic{i}_with_caption_c.png')\n",
    "    \n",
    "    caption_text = scene4_caption_Chinese.values[i-1][0]\n",
    "    img_frame_cap3(anime_path, caption_text).save(final_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "folder_path = 'image/scene4/chi/'\n",
    "\n",
    "for i in range(1, 21):\n",
    "    image_path = join(folder_path, f'pic{i}_with_caption_c.png')\n",
    "    display(Image.open(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "folder_path = 'image/scene4/chi/'\n",
    "\n",
    "num_cols = 4  # You can adjust the number of columns for the final poster\n",
    "num_rows = 5\n",
    "# num_rows = int(np.ceil(len(onlyfiles) / num_cols))\n",
    "\n",
    "poster = Image.new('RGB', (num_cols * 2000, num_rows * 1500))\n",
    "\n",
    "for i in range(1, 21):\n",
    "    img = Image.open(join(folder_path, f'pic{i}_with_caption_c.png'))\n",
    "    col = (i-1) % num_cols\n",
    "    row = (i-1) // num_cols\n",
    "    poster.paste(img.resize((2000, 1500)), (col * 2000, row * 1500))\n",
    "\n",
    "# Save the poster to a file\n",
    "poster.save('image/result/scene4_chi.jpg')\n",
    "\n",
    "\n",
    "poster.show()  # Display the final poster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed456a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install reportlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb56a5",
   "metadata": {},
   "source": [
    "## Put storybook into pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from PIL import Image\n",
    "\n",
    "def add_image_to_pdf(image_paths, pdf_path):\n",
    "    c = canvas.Canvas(pdf_path, pagesize=letter)\n",
    "    pdf_width, pdf_height = letter\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = Image.open(image_path)\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Calculate the scale to fit the image within the page while maintaining aspect ratio\n",
    "        scale = min(pdf_width / img_width, pdf_height / img_height)\n",
    "        scaled_width, scaled_height = img_width * scale, img_height * scale\n",
    "\n",
    "        # Calculate the position of the image on the page to center it\n",
    "        x_position = (pdf_width - scaled_width) / 2\n",
    "        y_position = (pdf_height - scaled_height) / 2\n",
    "\n",
    "        # Add the image to the PDF, resize it, and center it\n",
    "        c.drawImage(image_path, x_position, y_position, width=scaled_width, height=scaled_height)\n",
    "        \n",
    "        # Create a new page for the next image\n",
    "        c.showPage()\n",
    "    \n",
    "    c.save()\n",
    "    \n",
    "folder_path = 'image/result/'\n",
    "\n",
    "image_files = ['image/result/poster.png', 'image/result/Actor.png', 'image/result/scene1_eng.jpg', 'image/result/scene2.jpg', 'image/result/scene3_E.png', 'image/result/scene4_eng.jpg', 'image/result/scene1_chn.jpg', 'image/result/scene2_ch.jpg', 'image/result/scene3_C.png', 'image/result/scene4_chi.jpg']\n",
    "\n",
    "pdf_path = 'Assignment 10-Movie Story Book Final-Group10.pdf'\n",
    "\n",
    "add_image_to_pdf(image_files, pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9153a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
